{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katiehouse/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymmwr as pm\n",
    "import datetime\n",
    "\n",
    "\n",
    "def get_epi_data(date):\n",
    "    format_str = '%m/%d/%y'  # The format\n",
    "    dt = datetime.datetime.strptime(date, format_str).date()\n",
    "    epi = pm.date_to_epiweek(dt)\n",
    "    return epi.year, epi.week, epi.day\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\")\n",
    "fips_codes = pd.read_csv('../template/state_fips_codes.csv')\n",
    "\n",
    "\n",
    "# aggregate by state and nationally\n",
    "state_agg = df.groupby(['Province_State']).sum()\n",
    "us_nat = df.groupby(['Country_Region']).sum()\n",
    "df_state_nat = state_agg.append(us_nat)\n",
    "\n",
    "# drop unnecessary columns\n",
    "cols = list(range(0, 6))\n",
    "df_truth = df_state_nat.drop(df_state_nat.columns[cols], axis=1)\n",
    "\n",
    "# convert matrix to repeating row format\n",
    "df_truth = df_truth.unstack()\n",
    "df_truth = df_truth.reset_index()\n",
    "\n",
    "# get epi data from date\n",
    "df_truth['year'], df_truth['week'], df_truth['day'] = \\\n",
    "    zip(*df_truth['level_0'].map(get_epi_data))\n",
    "\n",
    "# rename columns\n",
    "df_truth = df_truth.rename(columns={0: \"value\",\n",
    "                                    \"level_1\": \"location_long\"})\n",
    "# Only visualize certain states\n",
    "states = ['US', 'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
    "          'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky',\n",
    "          'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri',\n",
    "          'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
    "          'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island',\n",
    "          'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
    "          'West Virginia', 'Wisconsin', 'Wyoming', 'District of Columbia']\n",
    "df_truth = df_truth[df_truth[\"location_long\"].isin(states)]\n",
    "\n",
    "# Get state IDs\n",
    "df_truth = df_truth.merge(fips_codes, left_on='location_long', right_on='state_name', how='left')\n",
    "df_truth.loc[df_truth[\"location_long\"] == \"US\", \"state_code\"] = \"US\"\n",
    "df_truth[\"state_code\"].replace({\"US\": 1000}, inplace=True)  # so that can be converted to int\n",
    "\n",
    "# convert FIPS code to int\n",
    "df_truth[\"state_code\"] = df_truth[\"state_code\"].astype(int)\n",
    "\n",
    "# add leading zeros to state code\n",
    "df_truth['state_code'] = df_truth['state_code'].apply(lambda x: '{0:0>2}'.format(x))\n",
    "\n",
    "# convert 1000 back to US\n",
    "df_truth[\"state_code\"].replace({\"1000\": \"US\"}, inplace=True)\n",
    "df_truth.loc[df_truth[\"location_long\"] == \"US\", \"state\"] = \"nat\"\n",
    "\n",
    "\n",
    "'''\n",
    "####################################\n",
    "# Daily truth data output for reference\n",
    "####################################\n",
    "'''\n",
    "\n",
    "# only output \"location\", \"epiweek\", \"value\"\n",
    "df_byday = df_truth.rename(columns={\"level_0\": \"date\", \"state_code\": \"location\", \"location_long\": \"location_name\"})\n",
    "\n",
    "# select columns\n",
    "df_byday = df_byday[[\"date\", \"location\", \"location_name\", \"value\"]]\n",
    "df_byday.to_csv('../data-processed/truth-cum-death.csv', index=False)\n",
    "\n",
    "'''\n",
    "####################################\n",
    "# Truth data output for visualization\n",
    "####################################\n",
    "'''\n",
    "# Observed data on the seventh day\n",
    "df_truth = df_truth[df_truth['day'] == 7]\n",
    "\n",
    "# add leading zeros to epi week\n",
    "df_truth['week'] = df_truth['week'].apply(lambda x: '{0:0>2}'.format(x))\n",
    "\n",
    "# define epiweek\n",
    "df_truth['epiweek'] = df_truth['year'].astype(str) + df_truth['week']\n",
    "\n",
    "# only output \"location\", \"epiweek\", \"value\"\n",
    "df_truth = df_truth.rename(columns={\"state\": \"location\"})\n",
    "df_truth_short = df_truth[[\"location\", \"epiweek\", \"value\"]]\n",
    "\n",
    "df_truth_short[\"value\"].replace({0: 0.1}, inplace=True)\n",
    "df_truth_short\n",
    "\n",
    "# write to json\n",
    "with open('flusight-master/covid-csv-tools/dist/state_actual/2019.json', 'w') as f:\n",
    "    f.write(df_truth_short.to_json(orient='records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "####################################\n",
    "# Truth data output for Zoltar & Scoring\n",
    "####################################\n",
    "'''\n",
    "# rename location\n",
    "df_truth_long = df_truth.rename(columns={\"week\": \"epiweek\",\n",
    "                                         \"state_code\": \"unit\",\n",
    "                                         \"level_0\": \"date\"})\n",
    "# get timezero\n",
    "df_truth_long['date'] = pd.to_datetime(df_truth_long['date'])\n",
    "\n",
    "# find week-ahead targets\n",
    "for i in range(4):\n",
    "    weeks_ahead = i + 1\n",
    "    days_back = 5 + (weeks_ahead * 7)  # timezero is on Mondays\n",
    "\n",
    "    df_calc = df_truth_long  # initialize df\n",
    "\n",
    "    # find timezero and target\n",
    "    df_calc['timezero'] = df_calc['date'] - datetime.timedelta(days=days_back)\n",
    "    df_calc['target'] = \"%i_week_ahead_cum\" % weeks_ahead\n",
    "\n",
    "    # select columns\n",
    "    df_calc = df_calc[[\"timezero\", \"unit\", \"target\", \"value\"]]\n",
    "\n",
    "    # concatenate truth\n",
    "    if i == 0:\n",
    "        df_out = df_calc\n",
    "    else:\n",
    "        df_out = pd.concat([df_out, df_calc])\n",
    "\n",
    "# write truth to csv\n",
    "df_out.to_csv('../data-processed/zoltar-truth-cum-death.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
